# Ubuntu System Management

### ğŸŒ± é…ç½®`ssh`

```
sudo apt install openssl-server
dpkg -l | grep ssh  # åº”è¯¥çœ‹åˆ° openssh-server
ps -e | grep ssh  # åº”è¯¥çœ‹åˆ° sshd
```

- å¦‚æœçœ‹åˆ°`sshd`é‚£è¯´æ˜`ssh-server`å·²ç»å¯åŠ¨äº†ã€‚
- å¦‚æœæ²¡æœ‰åˆ™å¯ä»¥è¿™æ ·å¯åŠ¨ï¼š

```
sudo /etc/init.d/ssh stop
sudo /etc/init.d/ssh start
```

- é…ç½®ç›¸å…³ï¼š
    - `ssh-server`é…ç½®æ–‡ä»¶ä½äº`/etc/ssh/sshd_config`ï¼Œåœ¨è¿™é‡Œå¯ä»¥å®šä¹‰`SSH`çš„æœåŠ¡ç«¯å£ï¼Œé»˜è®¤ç«¯å£æ˜¯`22`ï¼Œä½ å¯ä»¥è‡ªå·±å®šä¹‰æˆå…¶ä»–ç«¯å£å·ï¼Œå¦‚`222`ï¼›
    - æˆ–æŠŠé…ç½®æ–‡ä»¶ä¸­çš„`PermitRootLogin without-password`æ³¨é‡Šæ‰ï¼Œå†å¢åŠ ä¸€å¥`PermitRootLogin yes`ï¼Œç„¶åé‡å¯`SSH`æœåŠ¡ã€‚

- æ­¤æ—¶å·²ç»å¯ä»¥`ssh`ç™»å½•åŒæ—¶æ”¯æŒ`sftp`ã€‚

- sshå…å¯†ç ç™»å½•ï¼šå°†éœ€è¦å…å¯†ç çš„æœºå™¨çš„`ssh`å…¬é’¥`id_rsa.pub`æ‹·è´è‡³`${HOME}/.ssh/authorized_ssh`ã€‚


### ğŸŒ± é…ç½®`fail2ban`

```
sudo apt install fail2ban
sudo vi /etc/fail2ban/jail.local 

[sshd]
enabled = true
banaction = iptables-multiport
maxretry = 5
findtime = 900  # ban ip if fail for 5 times in 900 seconds
bantime = 1500  # ban ip for 1500 seconds
port = 130      # ssh port 130. do not need to specify if using port 22

sudo service fail2ban restart
```

### ğŸŒ± æ–°å»ºç”¨æˆ·

```
sudo adduser <user>  # æŒ‰ç…§æç¤ºæ¥ï¼Œä¸€èˆ¬é»˜è®¤å°±è¡Œ
```

- æŸ¥çœ‹ç”¨æˆ·ï¼š`cat /etc/passwd`
- åˆ é™¤ç”¨æˆ·ï¼š`deluser`
- è®¾ç½®`root`å¯†ç ï¼š`sudo passwd root`
- æ·»åŠ `sudoers`ï¼š

```
sudo su - 
visudo

# Allow members of group sudo to execute any command
%sudo   ALL=(ALL:ALL) ALL
ax      ALL=(ALL:ALL) ALL
```

- æ·»åŠ å…å¯†`sudoers`ï¼š

```
sudo su - 
visudo

# Allow members of group sudo to execute any command
%sudo   ALL=(ALL:ALL) ALL
ax      ALL=(ALL:ALL) NOPASSWD : ALL
```

#### åˆ‡æ¢ç”¨æˆ·

- `su`ä»¥åŠ`su -`ï¼Œ`su -l`åé¢ä¸åŠ ç”¨æˆ·ï¼Œåˆ™é»˜è®¤åˆ‡åˆ° `root`
- `su`æ˜¯ä¸æ”¹å˜å½“å‰å˜é‡ï¼ˆonly `.bashrc` will be sourcedï¼‰
- `su -`æ˜¯`su -l`çš„ç®€å†™ï¼Œâ€œæ¨¡æ‹Ÿäº†ä¸€æ¬¡ç™»å½•ï¼ˆloginï¼‰â€ï¼Œæ”¹å˜ä¸ºåˆ‡æ¢åˆ°ç”¨æˆ·çš„å˜é‡ï¼ˆexpericene a login process, usually `.bash_profile` and `.bashrc` will be sourcedï¼‰
- ä¹Ÿå°±æ˜¯è¯´`su`åªèƒ½è·å¾—`root`çš„æ‰§è¡Œæƒé™ï¼Œä¸èƒ½è·å¾—ç¯å¢ƒå˜é‡ï¼›è€Œ`su -`æ˜¯åˆ‡æ¢åˆ°`root`å¹¶è·å¾—`root`çš„ç¯å¢ƒå˜é‡åŠæ‰§è¡Œæƒé™

### ğŸŒ± ä¼ªåˆ†å¸ƒå¼`hadoop`

`hadoop`éœ€è¦`jdk 8`ã€‚
æ­£å¼éƒ¨ç½²åº”å½“ä¸º`hadoop`å•ç‹¬åˆ›å»ºè´¦å·ï¼Œå•æœºä¼ªåˆ†å¸ƒå¼é…ç½®ç€ç©å„¿ä¸€ä¸‹å°±ä¸ç”¨å•¦ã€‚
çœŸæ­£çš„åˆ†å¸ƒå¼å®‰è£…å¯ä»¥çœ‹`https://zhuanlan.zhihu.com/p/77938727`ã€‚
å®‰è£…æµç¨‹å¦‚ä¸‹ï¼š

- é…ç½®`ssh`ä»¥åŠå…å¯†ç™»å½•ï¼ˆå‚è€ƒæœ¬æ–‡ä»¶å¼€å¤´éƒ¨åˆ†ï¼‰ï¼›
- é…ç¯å¢ƒå˜é‡ï¼š
```
cd ~/Downloads
wget https://archive.apache.org/dist/hadoop/core/hadoop-3.2.0/hadoop-3.2.0.tar.gz
tar -zxvf hadoop-3.2.0.tar.gz
mv hadoop-3.2.0 /home/ax/opt/

gedit ~/.bashrc

# hadoop
export HADOOP_HOME=/home/ax/opt/hadoop-3.2.0
export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
export HADOOP_MAPRED_HOME=${HADOOP_HOME}
export HADOOP_COMMON_HOME=${HADOOP_HOME}
export HADOOP_HDFS_HOME=${HADOOP_HOME}
export YARN_HOME=${HADOOP_HOME}
export PATH=${PATH}:${HADOOP_HOME}/bin

source ~/.bashrc
hadoop version
```
- å•ç‹¬é…ç½®`${HADOOP_CONF_DIR}/hadoop-env.sh`ï¼š
```
gedit ${HADOOP_CONF_DIR}/hadoop-env.sh

# jvm
# in case hadoop does not recognize ${JAVA_HOME} exported in `/etc/profile`
# just let it happy
export JAVA_HOME=/opt/jvm/jdk
```
- ä¿®æ”¹4ä¸ªé…ç½®æ–‡ä»¶çš„`<configuration></configuration>`åŸŸï¼š
    - `core-site.xml`ï¼Œ`10497`æ˜¯`h`å’Œ`a`çš„`ASCII`ç ï¼Œå…¶å®éšä¾¿è°éƒ½è¡Œï¼š
    ```
    gedit ${HADOOP_CONF_DIR}/core-site.xml
    
    <configuration>
    <property>
      <name>fs.defaultFS</name>
      <value>hdfs://localhost:10497</value>
    </property>
    </configuration>
    ```
    - `hdfs-site.xml`ï¼Œç¬¬ä¸€ä¸ªæ˜¯`dfs`çš„å¤‡ä»½æ•°ç›®ï¼Œå•æœºç”¨`1`å°±è¡Œï¼Œåé¢ä¸¤ä¸ªæ˜¯`namenode`å’Œ`datanode`çš„ç›®å½•ï¼š
    ```
    gedit ${HADOOP_CONF_DIR}/hdfs-site.xml
    
    <configuration>
    <property>
      <name>dfs.replication</name>
      <value>1</value>
    </property>
    <property>
      <name>dfs.datanode.data.dir</name>
      <value>file:///home/ax/var/hadoop/hdfs/datanode</value>
    </property>
    <property>
      <name>dfs.namenode.name.dir</name>
      <value>file:///home/ax/var/hadoop/hdfs/namenode</value>
    </property>
    </configuration>
    ```
    - `mapred-site.xml`ï¼š
    ```
    gedit ${HADOOP_CONF_DIR}/mapred-site.xml
    
    <configuration>
      <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
      </property>
    </configuration>
    ```
    - `yarn-site.xml`ï¼š
    ```
    gedit ${HADOOP_CONF_DIR}/yarn-site.xml
    
    <configuration>
      <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
      </property>
    </configuration>
    ```
- æ ¼å¼åŒ–`HDFS`ï¼š
```
hadoop namenode -format
```
- å¯åŠ¨æˆ–å…³é—­ï¼š
```
${HADOOP_HOME}/sbin/start-all.sh
${HADOOP_HOME}/sbin/stop-all.sh
```
- æµ‹è¯•`hdfs`ï¼Œä¸æŠ¥é”™ï¼š
```
hdfs dfs -ls /
```
    - æˆ–è€…æµè§ˆå™¨ä¸­æ‰“å¼€`http://localhost:9870`ï¼Œè¿™ä¸ªæ˜¯`hadoop`çŠ¶æ€é¡µã€‚
    
## ğŸŒ± `spark`

```
cd ~/Downloads
wget http://apache.mirrors.hoobly.com/spark/spark-3.0.0-preview2/spark-3.0.0-preview2-bin-hadoop3.2.tgz
tar -xzvf spark-3.0.0-preview2-bin-hadoop3.2.tgz  
mv spark-3.0.0-preview2-bin-hadoop3.2 ~/opt/

gedit ~/.bashrc

# spark
export SPARK_HOME=/home/ax/opt/spark-3.0.0-preview2-bin-hadoop3.2
export PATH=${SPARK_HOME}/bin:${PATH}
```

```
cp $SPARK_HOME/conf/spark-env.sh.template $SPARK_HOME/conf/spark-env.sh
gedit $SPARK_HOME/conf/spark-env.sh

export SPARK_MASTER_IP=master
export SPARK_WORKER_MEMORY=4G
```

```
$SPARK_HOME/sbin/start-all.sh
jps
$SPARK_HOME/bin/run-example SparkPi
çœ‹çœ‹ä½ æœ‰æ²¡æœ‰å¾—åˆ°:
Pi is roughly 3.14716
```
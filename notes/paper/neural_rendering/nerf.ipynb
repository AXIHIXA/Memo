{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "415bcddb-6e73-46f2-9797-b0c49713483d",
   "metadata": {},
   "source": [
    "# NeRF（Neural Radiance Field）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d1b760-a656-4a20-8de4-d3cf8c68b6e0",
   "metadata": {},
   "source": [
    "- Reference：[【较真系列】讲人话-NeRF全解（原理+代码+公式）](https://www.bilibili.com/video/BV1CC411V7oq/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1461fb-c8d7-4082-a161-43eaa63dc5e2",
   "metadata": {},
   "source": [
    "- 广义理解定义\n",
    "  - 使用神经网络（MLP）来 *隐式地* 存储 3D 信息\n",
    "    - 显式的 3D 信息：有明确的 x，y，z 的值（mesh，voxel，点云…）\n",
    "    - 隐式的 3D 信息：无明确的 x，y，z 的值，只能输出指定角度的 2D 图片\n",
    "  - 训练时，使用给定静止场景下的若干张图片\n",
    "  - 推论：\n",
    "    - 模型 **不具有** 泛化能力\n",
    "    - 一个模型只能存储一个 3D 信息\n",
    "  - NeRF 是一个 8 层的 MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90445a3-1063-4421-a6dc-9e322657cbc3",
   "metadata": {},
   "source": [
    "- 相机模型：连接 3D 世界与 2D 图片\n",
    "  - 坐标系\n",
    "    - ![坐标系](https://learnopengl.com/img/getting-started/coordinate_systems.png)\n",
    "    - 模型坐标系（Model-space Coordinate，Local Coordinate）\n",
    "    - 世界坐标系（World-space Coordinate）\n",
    "    - 相机坐标系（Camera-space Coordinate，View-space Coordinate）\n",
    "    - 归一化相机坐标系（Normalized Device Coordinate，NDC，Clip-space Coordinate）\n",
    "    - 像素坐标系（Screen-space Coordinate）\n",
    "    - $\\mathbf{V}_{\\mathrm{clip}} \\in [-1, 1]^3 = \\mathbf{P} \\, \\mathbf{V} \\,  \\mathbf{M} \\, \\left( \\mathbf{V}_{\\mathrm{local}} \\in \\mathbb{R}^3 \\right)$\n",
    "  - 视锥和坐标变换\n",
    "    - ![视锥](./view_frustum.jpg)\n",
    "    - Perspective projection is to *stretch* the view frustum into a canonical view volume. \n",
    "    - The common practive is to map view-space coordinate $(x, y, z, 1)^\\top$ into NDC $(x^{'}, y^{'}, z^{'}, z)^\\top = (x_p, y_p, z_p, 1)^\\top$.\n",
    "      - For $x$ and $y$: \n",
    "        - The near plane is bounded by $(l, r, b, t)$ where $z = n$;\n",
    "        - An internal slice inside the frustum where $z = z$ should be bounded by $\\left( \\dfrac{z}{n} l, \\dfrac{z}{n} r, \\dfrac{z}{n} b, \\dfrac{z}{n} t \\right)$;\n",
    "        - This internal slice should be stretched into $[-1, 1, -1, 1]$;\n",
    "        - This yields the first two lines in the following equation.\n",
    "          - Note that the coefficients for $z$ are handled by the $w$ dimension in the actual projection matrix. \n",
    "      - For $z$:\n",
    "        - We need to map $z$ from $[n, f]$ into $[-1, 1]$.\n",
    "        - This yields the last three lines in the following equation. \n",
    "    - 那么：\n",
    "    $\n",
    "    \\left\\{\n",
    "    \\begin{aligned}\n",
    "    \\dfrac{x - \\dfrac{z}{n} l }{r - l} & = \\dfrac{x_p + 1}{2} \\\\\n",
    "    \\dfrac{y - \\dfrac{z}{n} b }{t - b} & = \\dfrac{y_p + 1}{2} \\\\\n",
    "    z_p & = \\dfrac{A z + B}{z} \\\\\n",
    "    z_p(n) & = -1 \\\\\n",
    "    z_p(f) & = 1\n",
    "    \\end{aligned}\n",
    "    \\right.\n",
    "    ;\n",
    "    $\n",
    "    - 解得投影变换矩阵如下：\n",
    "    $\n",
    "    \\mathbf{P} = \n",
    "    \\begin{pmatrix}\n",
    "       \\dfrac{2n}{r - l} & 0 & -\\dfrac{r + l}{r - l} & 0 \\\\\n",
    "       0 & \\dfrac{2n}{t - b} & -\\dfrac{t + b}{t - b} & 0 \\\\ \n",
    "       0 & 0 & -\\dfrac{n + f}{n - f} & \\dfrac{2nf}{n - f} \\\\ \n",
    "       0 & 0 & 1 & 0\n",
    "    \\end{pmatrix}\n",
    "    $\n",
    "    - 特别地，如果视锥是对称的（$-l = r = \\dfrac{w}{2}, -b = t = \\dfrac{h}{2}$），则\n",
    "    $\n",
    "    \\mathbf{P} = \n",
    "    \\begin{pmatrix}\n",
    "       \\dfrac{2n}{w} & 0 & 0 & 0 \\\\\n",
    "       0 & \\dfrac{2n}{h} & 0 & 0 \\\\ \n",
    "       0 & 0 & -\\dfrac{n + f}{n - f} & \\dfrac{2nf}{n - f} \\\\ \n",
    "       0 & 0 & 1 & 0\n",
    "    \\end{pmatrix}\n",
    "    $  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977dcc06-7596-4e2b-bd59-8d3fe57bd1c3",
   "metadata": {},
   "source": [
    "- 体渲染\n",
    "  - 属于渲染技术的分支\n",
    "  - 目的是解决云、烟、果冻等 *非刚体* 的渲染建模\n",
    "  - 将物质抽象为一团飘忽不定的粒子群\n",
    "  - 光线在穿过时，是光子在跟粒子发生碰撞的过程\n",
    "    - 吸收：光子被粒子吸收\n",
    "    - 放射：粒子本身发光\n",
    "    - 外射光：光子在冲击后被弹射\n",
    "    - 内射光：其他方向弹射来的粒子\n",
    "- NeRF 的假设：\n",
    "  - 物体是一团自发光的粒子\n",
    "  - 粒子有 *密度* 和 *颜色*\n",
    "  - 外射光和内射光抵消\n",
    "  - 多个粒子被渲染成指定角度的图片\n",
    "- NeRF 的输入和输出是什么？\n",
    "  - 模型的输入：\n",
    "    - 6D 向量 $(x, y, z, d_x, d_y, d_z)$ \n",
    "    - 将物体进行稀疏表示的 *单个粒子* 的 *位置* 和 *方向*，即 *位姿*\n",
    "  - 模型的输出：\n",
    "    - 4D 向量\n",
    "    - 该粒子的密度和颜色\n",
    "  - 【问题】\n",
    "    - 怎么得到这些粒子？\n",
    "      - 从图片和相机位姿计算射线\n",
    "      - 从射线上采样粒子\n",
    "    - 多少个粒子？这些粒子怎样批量输入？\n",
    "      - 训练时，一张图片取 1024 个像素，得到 1024 条射线\n",
    "      - 每条射线上采样 64 个粒子，总共得到 $64 \\times 1024$ 个粒子\n",
    "      - 粒子以 batch 的形式输入模型\n",
    "    - 这些粒子是怎么渲染成新的图片的？\n",
    "      - 分别计算图片中每一个像素的颜色\n",
    "      - 计算该像素对应的光线和粒子\n",
    "      - 将这些粒子通过体渲染公式累加\n",
    "      - 得到该像素的最终颜色\n",
    "- NeRF 的训练流程\n",
    "  - 输入同一个场景的若干张照片\n",
    "  - 根据每张照片的每个像素，计算出光线，采样出粒子（粒子有位姿，但没有密度和颜色）\n",
    "  - 用 NeRF 模型预测这些粒子的密度和颜色\n",
    "  - 用这些粒子，按照体渲染的方法计算出对应像素的颜色的预测值\n",
    "  - 像素颜色预测值和 GT 做 MSE\n",
    "- NeRF 的 推理流程\n",
    "  - 给定新视角，渲染一张 $400 \\times 400$ 的图片\n",
    "  - 模型输入：$400 \\times 400$ 条射线上分别采样 $64$ 个点（自带位置和方向）\n",
    "  - 模型输出：$(400 \\times 400 \\times 192, 4)$，这么多个点的颜色和密度\n",
    "  - 进行体渲染\n",
    "- NeRF 的总结\n",
    "  - 隐式渲染（Neural Rendering）的鼻祖论文\n",
    "  - 核心内容：\n",
    "    - 体渲染\n",
    "    - 位置编码\n",
    "    - adaptive sampling\n",
    "  - 缺点：\n",
    "    - 很慢——训练、推理都慢\n",
    "    - 只能表达静态场景\n",
    "    - 不支持全局光照\n",
    "    - 没有泛化能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbcb097-3446-402e-a6d7-864766b3a5e4",
   "metadata": {},
   "source": [
    "- 粒子的采集——生成原理\n",
    "  - 对于空间上得我某一个发光粒子：\n",
    "    - 空间坐标 $(x, y, z)$\n",
    "    - 发射的光线通过 *相机模型* 成为图片上的像素坐标 $(u, v)$\n",
    "    - 粒子颜色即像素颜色\n",
    "  - 反之，对于图片上的某一个像素 $(u, v)$ 的颜色\n",
    "    - 可以看做沿着某一条射线上的无数个发光点的 *和*\n",
    "    - 利用相机模型，反推射线 $\\mathbf{r}(t) = \\mathbf{o} + t \\mathbf{d}, \\ 0 < t < +\\infty$\n",
    "      - $\\mathbf{o}$ 为射线原点（即相机位置）\n",
    "      - $\\mathbf{d}$ 为方向（相机位置到 near plane 上这个像素所在位置）\n",
    "      - $t$ 为距离\n",
    "      - $\\mathbf{V}_{\\mathrm{screen}} = (u, v) \\to \\mathbf{V}_{\\mathrm{clip}} = \\left( \\dfrac{2u}{r - l} - 1, \\dfrac{2v}{t - b} - 1, -1, 1 \\right) \\to  \\mathbf{V}_{\\mathrm{world}} = \\left( \\mathbf{P} \\, \\mathbf{V} \\right)^{-1} \\, \\mathbf{V}_{\\mathrm{clip}}$. \n",
    "    - 对于整张图片，共有 $(H, W)$ 条射线！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf58c11b-13c4-4641-9e10-baedacd99864",
   "metadata": {},
   "source": [
    "- 粒子的采集——采样原理\n",
    "  - 采样时 $t$ 的范围不是 $[0, +\\infty)$，而是设置了 near = 2，far = 6\n",
    "  - 在 near 和 far 之间均匀采样 64 个点\n",
    "  - $t_i = U \\left[ t_n + \\dfrac{i - 1}{N} (t_f - t_n), t_n + \\dfrac{i}{N} (t_f - t_n) \\right]$（还加了一点噪声，模拟采样鲁棒性）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f70f2fe-d14f-4bf6-9018-e933f8b20f8b",
   "metadata": {},
   "source": [
    "- NeRF 的模型结构\n",
    "  - 概述\n",
    "    - 8 层全连接层（MLP）\n",
    "    - 半路再次输入位置坐标\n",
    "    - 后半路输出密度 $\\sigma$\n",
    "      - 搞定密度之后才输入方向视角的原因：\n",
    "      - 观测视角不应该影响粒子的密度，只应该影响粒子的颜色 \n",
    "    - 后半路输入视角坐标\n",
    "    - 最后输出颜色 RGB\n",
    "  - 输入是 60 维位置坐标 和 24 维视角坐标\n",
    "    - 实验发现，只输入 3D 位置和视角时，模型细节丢失（缺乏高频信息）\n",
    "    - 引入位置编码 $\\gamma(p) = \\left( \\sin(2^0 \\pi p), \\cos(2^0 \\pi p ), \\cdots, \\sin(2^{L-1} \\pi p), \\cos(2^{L-1} \\pi p) \\right)$，共 $2L$ 维\n",
    "      - $p$ 需要已经归一化到 $[-1, 1]$ \n",
    "      - 对空间坐标 $\\mathbf{x} = (x, y, z)$，$L = 10$，$\\gamma(\\mathbf{x})$ 是 60D\n",
    "      - 对视角坐标 $\\mathbf{d} = (d_x, d_y, d_z)$，$L = 4$，$\\gamma(\\mathbf{d})$ 是 24D\n",
    "    - 在代码中，加上初始值，$\\gamma(\\mathbf{x})$ 是 63D，$\\gamma(\\mathbf{d})$ 是 27D\n",
    "  - 自监督 Loss\n",
    "    - GT 为图片某一像素的 RGB\n",
    "    - 将该像素对应光线上的粒子颜色进行求和\n",
    "    - 粒子的颜色 和 该像素颜色的预测值 做 MSE $\\mathcal{L} = \\sum_{r \\in R} || \\hat{C}(r) - C(r) ||_2^2$\n",
    "    - R 是每个 batch 的射线（1024 条）\n",
    "- NeRF 的 粗模型 和 细模型\n",
    "  - 问题：\n",
    "    - 无效区域（空白和被遮挡的区域）均匀采样\n",
    "    - 我们希望有效区域多采样，无效区域少采样或不采样\n",
    "  - 解决方法：\n",
    "    - 根据 粗模型预测出的概率密度 进行 再次采样\n",
    "  - NeRF 模型由两个模型组成，两个 8 层的 MLP 串联到一起\n",
    "    - 粗模型：输入均匀采样的粒子，输出密度\n",
    "    - 细模型：根据密度，二次采样\n",
    "    - 最后输出：采用细模型的输出\n",
    "    - 粗模型和细模型结构相同\n",
    "  - 细模型如何进行二次采样？\n",
    "    - 根据粗模型的结果，进行逆变换采样\n",
    "      - （如何使得采样结果符合某概率分布，如正态分布？答：均匀分布 + 逆变换采样）\n",
    "      - 对于每条光线，重新采样 128 个粒子\n",
    "      - 与之前粗模型采样出的 64 个粒子加在一起\n",
    "      - 即：每条光线总共采样 192 个粒子\n",
    "    - 逆变换采样\n",
    "      - 对于每条射线上的粒子颜色前的权重做 softmax\n",
    "        - 就是下面 `raw2output` 公式中的 $\\alpha_n (1 - \\alpha_0) (1 - \\alpha_1) \\cdots (1 - \\alpha_{n - 1})$\n",
    "      - 此时，新的权重和为 1，可看做 PDF\n",
    "      - 对 PDF 做前缀和，生成 CDF\n",
    "      - 计算 CDF 的反函数\n",
    "      - 用均匀分布生成一个随机数，`invert_cdf(uniform_real_distribution(0, 1)) = r`\n",
    "      - 得到的 r 就是符合 PDF 分布的随机数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0c397b-4983-45ca-9964-01cceb425f2c",
   "metadata": {},
   "source": [
    "- 体渲染：对光线上的粒子颜色进行求和\n",
    "  - 连续版本：\n",
    "    - $\\displaystyle C = \\int_0^{+\\infty} T(s) \\sigma(s) C(s) \\mathrm{d}s = \\sum_i T_i \\alpha_i C_i$\n",
    "    - $T(s)$：在 s 点之前，光线没有被阻挡的概率，【由两个已知求出来】\n",
    "      - $T(s) = \\exp(-\\int_0^s \\sigma(t) \\mathrm{d}t)$，这是按概率论列微分方程解出来的解析解\n",
    "    - $\\sigma(s)$：在 s 点处，光线碰撞粒子（光线被粒子阻碍）的概率，【已知】\n",
    "    - $C(s)$：在 s 点处，粒子的颜色，【已知】\n",
    "  - 离散化：\n",
    "    - 将光线 $[0, s]$ 划分为 N 个等间距区间 $[T_n, T_{n+1}]$，$n = 0, 1, \\cdots, N$\n",
    "      - 间隔长度为 $\\delta_n$\n",
    "      - 假设区间内的密度 $\\sigma_n$ 和颜色 $C_n$ 固定\n",
    "    - $\\displaystyle C(r) = \\sum_{n=0}^N C_n e^{- \\sum_{i=0}^{n-1} \\sigma_i \\delta_i} (1 - e^{- \\sigma_n \\delta_n}) = \\sum_n C_n T_n \\alpha_n$，其中：\n",
    "      - $C_n$ 叫颜色，是之前通过球谐函数算出来的 RGB 值\n",
    "      - $T_n = e^{- \\sum_{i=0}^{n-1} \\sigma_i \\delta_i}$ 叫没有被阻挡的概率\n",
    "        - $T_n = 0$ 的话直接不用算了，因为被挡住了\n",
    "      - $\\alpha_n = 1 - e^{- \\sigma_n \\delta_n}$ 叫不透明度\n",
    "  - 代码中对公式做了进一步简化（见函数 `raw2output`）：\n",
    "    - $\\displaystyle \\hat{C} = \\sum_{n=0}^N C_n e^{- \\sum_{j=1}^{i-1} \\sigma_j \\delta_j} (1 - e^{- \\sigma_i \\delta_i}) = \\sum_{n=0}^N C_n T_n \\alpha_n$\n",
    "    - 其中 $T_n = \n",
    "    e^{- \\sum_{j=1}^{i-1} \\sigma_j \\delta_j} = \n",
    "    e^{ - \\left(\\sigma_0 \\delta_0 + \\sigma_1 \\delta_1 + \\sigma_2 \\delta_2 + \\cdots + \\sigma_{n-1} \\delta_{n-1} \\right) } = \n",
    "    e^{- \\sigma_0 \\delta_0} \\cdot e^{- \\sigma_1 \\delta_1} \\cdot e^{- \\sigma_2 \\delta_2} \\cdots e^{- \\sigma_{n-1} \\delta_{n-1}}\n",
    "    $\n",
    "    - 在上式中代入 $\\alpha_n = 1 - e^{- \\sigma_n \\delta_n}$，得：$T_n = (1 - \\alpha_0) (1 - \\alpha_1) (1 - \\alpha_2) \\cdots (1 - \\alpha_{n - 1})$\n",
    "    - 则 $\n",
    "    \\displaystyle \n",
    "    \\begin{aligned} \n",
    "        \\hat{C} & = \\sum_{n=0}^N C_n \\alpha_n (1 - \\alpha_0) (1 - \\alpha_1) \\cdots (1 - \\alpha_{n - 1}) \\\\ \n",
    "                & = C_0 \\alpha_0 + C_1 \\alpha_1 (1 - \\alpha_0) + C_2 \\alpha_2 (1 - \\alpha_0) (1 - \\alpha_1) + \\cdots + C_n \\alpha_n (1 - \\alpha_0) (1 - \\alpha_1) \\cdots (1 - \\alpha_{n - 1})\n",
    "    \\end{aligned}\n",
    "    $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ded057-4b74-4a05-aa92-80384427e769",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8159b21b-e9b2-4ab6-81d6-89af5c648897",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
